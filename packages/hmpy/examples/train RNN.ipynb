{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kike\\Documents\\GitHub\\NEP-V5\\packages\\hmpy\\examples\n",
      "\n",
      "*************  Model =  bien_bateo ***********\n",
      "\n",
      "C:\\Users\\kike\\Documents\\GitHub\\NEP-V5\\packages\\hmpy\\examples/data/segmented_dnn/bien_bateo\n",
      "Number of samples: 15\n",
      "Data correctly read and filtered\n",
      "\n",
      "*************  Model =  karate ***********\n",
      "\n",
      "C:\\Users\\kike\\Documents\\GitHub\\NEP-V5\\packages\\hmpy\\examples/data/segmented_dnn/karate\n",
      "Number of samples: 15\n",
      "Data correctly read and filtered\n",
      "\n",
      "*************  Model =  espada ***********\n",
      "\n",
      "C:\\Users\\kike\\Documents\\GitHub\\NEP-V5\\packages\\hmpy\\examples/data/segmented_dnn/espada\n",
      "Number of samples: 15\n",
      "Data correctly read and filtered\n",
      "minimun value of samples:  171\n",
      "Building a DNN model\n",
      "Type Model = DNN , Type data= 3IMU_acc\n",
      "dataset obtained\n",
      "Building a DNN model\n",
      "Type Model = DNN , Type data= 3IMU_acc\n",
      "dataset obtained\n",
      "Building a DNN model\n",
      "Type Model = DNN , Type data= 3IMU_acc\n",
      "dataset obtained\n",
      "Libraries loaded\n",
      "2520\n",
      "2520\n",
      "2520\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]]\n",
      "(45, 168)\n",
      "(45, 3)\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Luis Enrique Coronado Zuniga\n",
    "# You are free to use, change, or redistribute the code in any way you wish\n",
    "# but please maintain the name of the original author.\n",
    "# This code comes with no warranty of any kind.\n",
    "\n",
    "\n",
    "#%%\n",
    "import os\n",
    "from numpy import*\n",
    "from deep_hmpy import*\n",
    "from hmpy import*\n",
    "import timeit\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "print dir_path\n",
    "seed = 1\n",
    "\n",
    "#Configuration of the models\n",
    "create_models = False\n",
    "features = False\n",
    "\n",
    "#Define the name of the gesture\n",
    "name_model1 = \"bien_bateo\"\n",
    "name_model2 = \"karate\"\n",
    "name_model3 = \"espada\"\n",
    "\n",
    "\n",
    "# ************************************** Gesture, data and paths definitions *********************************************\n",
    "\n",
    "#Define the path to save the models\n",
    "path_to_save = dir_path + \"/data/models/\"\n",
    "\n",
    "#Define the path of the gesture folders\n",
    "path_to_load = dir_path + \"/data/segmented_dnn/\"\n",
    "\n",
    "#Define id (name) of the files in the datatest, example <acc(1)>.txt, example <acc(2)>.txt , ....\n",
    "files_id = \"acc\"\n",
    "\n",
    "#Crate a new model\n",
    "create_models = True\n",
    "\n",
    "gest1 = GestureModel(name_model1,path_to_load,path_to_save)\n",
    "gest2 = GestureModel(name_model2,path_to_load,path_to_save)\n",
    "gest3 = GestureModel(name_model3,path_to_load,path_to_save)\n",
    "\n",
    "\n",
    "#Create a list of models\n",
    "list_models = [gest1,gest2,gest3]\n",
    "\n",
    "value = pre1D.equal_inputs(list_models, \"min\")\n",
    "print  \"minimun value of samples: \",  value*3\n",
    "\n",
    "if(create_models == True):\n",
    "    gest1.buildDNN_model(\"3IMU_acc\", features, value=value)\n",
    "    gest2.buildDNN_model(\"3IMU_acc\", features, value=value)\n",
    "    gest3.buildDNN_model(\"3IMU_acc\", features, value=value)\n",
    "\n",
    "#Update list of models\n",
    "list_models = [gest1,gest2,gest3]\n",
    "\n",
    "# ******************************************** DNN training ***********************************************\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import timeit\n",
    "print \"Libraries loaded\"\n",
    "\n",
    "\n",
    "dnn_dataset = concatenate((list_models[0].dnn_dataset,list_models[1].dnn_dataset), axis=0)\n",
    "i = 2\n",
    "n = size(list_models)\n",
    "\n",
    "while(i < n):\n",
    "    dnn_dataset = concatenate((dnn_dataset,list_models[i].dnn_dataset), axis=0)\n",
    "    i = i + 1\n",
    "X = dnn_dataset\n",
    "\n",
    "print size(list_models[0].dnn_dataset)\n",
    "print size(list_models[1].dnn_dataset)\n",
    "print size(list_models[2].dnn_dataset)\n",
    "\n",
    "\n",
    "#Outputs\n",
    "n_classes = size(list_models)\n",
    "training_examples1 = 15\n",
    "Y = pre1D.set_outputs(n_classes,training_examples1)\n",
    "\n",
    "print Y\n",
    "\n",
    "n_examples, n_inputs = shape(X)\n",
    "print shape(X)\n",
    "print shape(Y)\n",
    "\n",
    "random.seed(seed)\n",
    "print \"Data loaded\"\n",
    "\n",
    "#%%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [[i for i in range(100)]]\n",
    "data = np.array(data, dtype=float)\n",
    "target = [[i for i in range(1,101)]]\n",
    "target = np.array(target, dtype=float)\n",
    "\n",
    "data = data.reshape((1, 1, 100)) \n",
    "target = target.reshape((1, 1, 100)) \n",
    "x_test=[i for i in range(100,200)]\n",
    "x_test=np.array(x_test).reshape((1,1,100));\n",
    "y_test=[i for i in range(101,201)]\n",
    "y_test=np.array(y_test).reshape(1,1,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "    14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "    28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "    42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "    56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "    70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "    84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "    98.  99.]]]\n",
      "[[[100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      "   118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      "   136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153\n",
      "   154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171\n",
      "   172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189\n",
      "   190 191 192 193 194 195 196 197 198 199]]]\n",
      "[[[101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118\n",
      "   119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136\n",
      "   137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154\n",
      "   155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172\n",
      "   173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190\n",
      "   191 192 193 194 195 196 197 198 199 200]]]\n"
     ]
    }
   ],
   "source": [
    "print data\n",
    "print x_test\n",
    "print y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()  \n",
    "model.add(LSTM(100, input_shape=(1, 100),return_sequences=True))\n",
    "model.add(Dense(100))\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(data, target, nb_epoch=10, batch_size=1, verbose=2,validation_data=(X, Y))\n",
    "\n",
    "toc=timeit.default_timer()\n",
    "tm = toc -tic\n",
    "\n",
    "print \"Fit complete in\" , toc - tic , \"seconds\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
